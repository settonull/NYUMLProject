runRecommender <- function(method, scheme){
Recommender(getData(scheme, "train"), method[[1]])
}
#Get the RMSE and MAE of the algorithms
predError <- function(method, scheme){
print(show(method))
preds <- predict(method, getData(scheme, "known"), type="ratings")
rmse <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[1]]
mae <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[3]]
merge(rmse, mae)
}
recs <- lapply(algorithm_list, runRecommender, ev_scheme)
#Get the errors and place in a data frame
recommender_errors <- sapply(recs, predError, ev_scheme) %>%
t() %>%
as.data.frame() %>%
rownames_to_column %>%
as_tibble() %>%
rename(Model = rowname, RMSE = x, MAE = y) %>%
mutate(RMSE = as.numeric(RMSE),
MAE = as.numeric(MAE)) %>%
arrange(RMSE, MAE)
#original best algorithms
best_algorithms <- c("UBCF_cosine_5", "UBCF_pearson_5", "UBCF_jaccard_5", "IBCF_cosine_5", "IBCF_pearson_5", "IBCF_jaccard_5")
#all possible combinations
best_algorithm_list <- combn(best_algorithms, 3) %>%  t() %>% as_tibble()
#create the hybrid recommenders
runHybridRecommender <- function(method, rec_list){
recs <- method %>%
unlist(., recursive = TRUE, use.names = FALSE)
HybridRecommender(rec_list[[recs[1]]],
rec_list[[recs[2]]],
rec_list[[recs[3]]])
}
hybrids <- apply(best_algorithm_list, 1, runHybridRecommender, recs)
#Get the error data frame as before
hybrid_errors <- sapply(hybrids, predError, ev_scheme) %>%
t() %>%
as.data.frame() %>%
rownames_to_column %>%
as_tibble() %>%
rename(Model = rowname, RMSE = x, MAE = y) %>%
mutate(RMSE = as.numeric(RMSE),
MAE = as.numeric(MAE)) %>%
add_row(Model = "Best Single", RMSE = min(recommender_errors$RMSE), MAE = min(recommender_errors$MAE)) %>%
mutate(RMSE_diff = (RMSE - min(recommender_errors$RMSE))/min(recommender_errors$RMSE) * 100,
MAE_diff = (MAE - min(recommender_errors$MAE))/min(recommender_errors$MAE) * 100) %>%
arrange(RMSE, MAE)
rm(algorithm_list)
readIn_path <- paste0('data/rec/before_dubIndex/data', 2013, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', 2013, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
#Algorithms to try
algorithm_list <- list(
Random = list(name = "RANDOM", param = NULL),
IBCF_cosine_5 = list(name = 'IBCF', param = list(k = 5, method = "cosine", normalize = NULL)),
IBCF_pearson_5 = list(name = 'IBCF', param = list(k = 5, method = "pearson", normalize = NULL)),
IBCF_jaccard_5 = list(name = 'IBCF', param = list(k = 5, method = "jaccard", normalize = NULL)),
UBCF_cosine_5 = list(name = 'UBCF', param = list(nn = 5, method = "cosine", normalize = NULL)),
UBCF_pearson_5 = list(name = 'UBCF', param = list(nn = 5, method = "pearson", normalize = NULL)),
UBCF_jaccard_5 = list(name = 'UBCF', param = list(nn = 5, method = "jaccard", normalize = NULL))
)
#Create the algorithms
runRecommender <- function(method, scheme){
Recommender(getData(scheme, "train"), method[[1]])
}
#Get the RMSE and MAE of the algorithms
predError <- function(method, scheme){
print(show(method))
preds <- predict(method, getData(scheme, "known"), type="ratings")
rmse <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[1]]
mae <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[3]]
merge(rmse, mae)
}
recs <- lapply(algorithm_list, runRecommender, ev_scheme)
#Get the errors and place in a data frame
recommender_errors <- sapply(recs, predError, ev_scheme) %>%
t() %>%
as.data.frame() %>%
rownames_to_column %>%
as_tibble() %>%
rename(Model = rowname, RMSE = x, MAE = y) %>%
mutate(RMSE = as.numeric(RMSE),
MAE = as.numeric(MAE)) %>%
arrange(RMSE, MAE)
#original best algorithms
best_algorithms <- c("UBCF_cosine_5", "UBCF_pearson_5", "UBCF_jaccard_5", "IBCF_cosine_5", "IBCF_pearson_5", "IBCF_jaccard_5")
#all possible combinations
best_algorithm_list <- combn(best_algorithms, 3) %>%  t() %>% as_tibble()
#create the hybrid recommenders
runHybridRecommender <- function(method, rec_list){
recs <- method %>%
unlist(., recursive = TRUE, use.names = FALSE)
HybridRecommender(rec_list[[recs[1]]],
rec_list[[recs[2]]],
rec_list[[recs[3]]])
}
hybrids <- apply(best_algorithm_list, 1, runHybridRecommender, recs)
#Get the error data frame as before
hybrid_errors <- sapply(hybrids, predError, ev_scheme) %>%
t() %>%
as.data.frame() %>%
rownames_to_column %>%
as_tibble() %>%
rename(Model = rowname, RMSE = x, MAE = y) %>%
mutate(RMSE = as.numeric(RMSE),
MAE = as.numeric(MAE)) %>%
add_row(Model = "Best Single", RMSE = min(recommender_errors$RMSE), MAE = min(recommender_errors$MAE)) %>%
mutate(RMSE_diff = (RMSE - min(recommender_errors$RMSE))/min(recommender_errors$RMSE) * 100,
MAE_diff = (MAE - min(recommender_errors$MAE))/min(recommender_errors$MAE) * 100) %>%
arrange(RMSE, MAE)
readIn_path <- paste0('data/rec/before_dubIndex/data', 2013, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', 2013, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
#Algorithms to try
algorithm_list <- list(
Random = list(name = "RANDOM", param = NULL),
IBCF_cosine_5 = list(name = 'IBCF', param = list(k = 5, method = "cosine", normalize = NULL)),
IBCF_pearson_5 = list(name = 'IBCF', param = list(k = 5, method = "pearson", normalize = NULL)),
IBCF_jaccard_5 = list(name = 'IBCF', param = list(k = 5, method = "jaccard", normalize = NULL)),
UBCF_cosine_5 = list(name = 'UBCF', param = list(nn = 5, method = "cosine", normalize = NULL)),
UBCF_pearson_5 = list(name = 'UBCF', param = list(nn = 5, method = "pearson", normalize = NULL)),
UBCF_jaccard_5 = list(name = 'UBCF', param = list(nn = 5, method = "jaccard", normalize = NULL))
)
#Create the algorithms
runRecommender <- function(method, scheme){
Recommender(getData(scheme, "train"), method[[1]])
}
#Get the RMSE and MAE of the algorithms
predError <- function(method, scheme){
print(show(method))
preds <- predict(method, getData(scheme, "known"), type="ratings")
rmse <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[1]]
mae <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[3]]
merge(rmse, mae)
}
recs <- lapply(algorithm_list, runRecommender, ev_scheme)
#Get the errors and place in a data frame
recommender_errors <- sapply(recs, predError, ev_scheme) %>%
t() %>%
as.data.frame() %>%
rownames_to_column %>%
as_tibble() %>%
rename(Model = rowname, RMSE = x, MAE = y) %>%
mutate(RMSE = as.numeric(RMSE),
MAE = as.numeric(MAE)) %>%
arrange(RMSE, MAE)
#original best algorithms
best_algorithms <- c("UBCF_cosine_5", "UBCF_pearson_5", "UBCF_jaccard_5", "IBCF_cosine_5", "IBCF_pearson_5", "IBCF_jaccard_5")
#all possible combinations
best_algorithm_list <- combn(best_algorithms, 3) %>%  t() %>% as_tibble()
#create the hybrid recommenders
runHybridRecommender <- function(method, rec_list){
recs <- method %>%
unlist(., recursive = TRUE, use.names = FALSE)
HybridRecommender(rec_list[[recs[1]]],
rec_list[[recs[2]]],
rec_list[[recs[3]]])
}
hybrids <- apply(best_algorithm_list, 1, runHybridRecommender, recs)
#Get the error data frame as before
hybrid_errors <- sapply(hybrids, predError, ev_scheme) %>%
t() %>%
as.data.frame() %>%
rownames_to_column %>%
as_tibble() %>%
rename(Model = rowname, RMSE = x, MAE = y) %>%
mutate(RMSE = as.numeric(RMSE),
MAE = as.numeric(MAE)) %>%
add_row(Model = "Best Single", RMSE = min(recommender_errors$RMSE), MAE = min(recommender_errors$MAE)) %>%
mutate(RMSE_diff = (RMSE - min(recommender_errors$RMSE))/min(recommender_errors$RMSE) * 100,
MAE_diff = (MAE - min(recommender_errors$MAE))/min(recommender_errors$MAE) * 100) %>%
arrange(RMSE, MAE)
rm(algorithm_list)
View(recommender_errors)
View(hybrid_errors)
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(k = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% drop_na() %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(k = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% drop_na() %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
readIn_path <- paste0('data/rec/before_dubIndex/data', 2013, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', 2013, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
#Algorithms to try
algorithm_list <- list(
Random = list(name = "RANDOM", param = NULL),
IBCF_cosine_5 = list(name = 'IBCF', param = list(k = 5, method = "cosine", normalize = NULL)),
IBCF_pearson_5 = list(name = 'IBCF', param = list(k = 5, method = "pearson", normalize = NULL)),
IBCF_jaccard_5 = list(name = 'IBCF', param = list(k = 5, method = "jaccard", normalize = NULL)),
UBCF_cosine_5 = list(name = 'UBCF', param = list(nn = 5, method = "cosine", normalize = NULL)),
UBCF_pearson_5 = list(name = 'UBCF', param = list(nn = 5, method = "pearson", normalize = NULL)),
UBCF_jaccard_5 = list(name = 'UBCF', param = list(nn = 5, method = "jaccard", normalize = NULL))
)
#Create the algorithms
runRecommender <- function(method, scheme){
Recommender(getData(scheme, "train"), method[[1]])
}
#Get the RMSE and MAE of the algorithms
predError <- function(method, scheme){
print(show(method))
preds <- predict(method, getData(scheme, "known"), type="ratings")
rmse <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[1]]
mae <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[3]]
merge(rmse, mae)
}
recs <- lapply(algorithm_list, runRecommender, ev_scheme)
#Get the errors and place in a data frame
recommender_errors <- sapply(recs, predError, ev_scheme) %>%
t() %>%
as.data.frame() %>%
rownames_to_column %>%
as_tibble() %>%
rename(Model = rowname, RMSE = x, MAE = y) %>%
mutate(RMSE = as.numeric(RMSE),
MAE = as.numeric(MAE)) %>%
arrange(RMSE, MAE)
#original best algorithms
best_algorithms <- c("UBCF_cosine_5", "UBCF_pearson_5", "UBCF_jaccard_5", "IBCF_cosine_5", "IBCF_pearson_5", "IBCF_jaccard_5")
#all possible combinations
best_algorithm_list <- combn(best_algorithms, 3) %>%  t() %>% as_tibble()
#create the hybrid recommenders
runHybridRecommender <- function(method, rec_list){
recs <- method %>%
unlist(., recursive = TRUE, use.names = FALSE)
HybridRecommender(rec_list[[recs[1]]],
rec_list[[recs[2]]],
rec_list[[recs[3]]])
}
hybrids <- apply(best_algorithm_list, 1, runHybridRecommender, recs)
#Get the error data frame as before
hybrid_errors <- sapply(hybrids, predError, ev_scheme) %>%
t() %>%
as.data.frame() %>%
rownames_to_column %>%
as_tibble() %>%
rename(Model = rowname, RMSE = x, MAE = y) %>%
mutate(RMSE = as.numeric(RMSE),
MAE = as.numeric(MAE)) %>%
add_row(Model = "Best Single", RMSE = min(recommender_errors$RMSE), MAE = min(recommender_errors$MAE)) %>%
mutate(RMSE_diff = (RMSE - min(recommender_errors$RMSE))/min(recommender_errors$RMSE) * 100,
MAE_diff = (MAE - min(recommender_errors$MAE))/min(recommender_errors$MAE) * 100) %>%
arrange(RMSE, MAE)
rm(algorithm_list)
View(hybrid_errors)
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(k = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% drop_na() %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(k = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% drop_na() %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(k = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% drop_na() %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
readIn_path <- paste0('data/rec/before_dubIndex/data', 2013, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', 2013, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
data_mat %>% as('data.frame') %>% View()
algorithm_list <- list(
Random = list(name = "RANDOM", param = NULL),
IBCF_cosine_5 = list(name = 'IBCF', param = list(k = 5, method = "cosine", normalize = NULL)),
IBCF_pearson_5 = list(name = 'IBCF', param = list(k = 5, method = "pearson", normalize = NULL)),
IBCF_jaccard_5 = list(name = 'IBCF', param = list(k = 5, method = "jaccard", normalize = NULL)),
UBCF_cosine_5 = list(name = 'UBCF', param = list(nn = 5, method = "cosine", normalize = NULL)),
UBCF_pearson_5 = list(name = 'UBCF', param = list(nn = 5, method = "pearson", normalize = NULL)),
UBCF_jaccard_5 = list(name = 'UBCF', param = list(nn = 5, method = "jaccard", normalize = NULL))
)
runRecommender <- function(method, scheme){
Recommender(getData(scheme, "train"), method[[1]])
}
predError <- function(method, scheme){
print(show(method))
preds <- predict(method, getData(scheme, "known"), type="ratings")
rmse <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[1]]
mae <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[3]]
merge(rmse, mae)
}
recs <- lapply(algorithm_list, runRecommender, ev_scheme)
recommender_errors <- sapply(recs, predError, ev_scheme) %>%
t() %>%
as.data.frame() %>%
rownames_to_column %>%
as_tibble() %>%
rename(Model = rowname, RMSE = x, MAE = y) %>%
mutate(RMSE = as.numeric(RMSE),
MAE = as.numeric(MAE)) %>%
arrange(RMSE, MAE)
View(recommender_errors)
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "UBCF", param = list(k = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% drop_na() %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "UBCF", param = list(nn = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% drop_na() %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
readIn_path <- paste0('data/rec/before_dubIndex/data', 2013, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', 2013, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
#Algorithms to try
algorithm_list <- list(
Random = list(name = "RANDOM", param = NULL),
IBCF_cosine_5 = list(name = 'IBCF', param = list(k = 5, method = "cosine", normalize = NULL)),
IBCF_pearson_5 = list(name = 'IBCF', param = list(k = 5, method = "pearson", normalize = NULL)),
IBCF_jaccard_5 = list(name = 'IBCF', param = list(k = 5, method = "jaccard", normalize = NULL)),
UBCF_cosine_5 = list(name = 'UBCF', param = list(nn = 5, method = "cosine", normalize = NULL)),
UBCF_pearson_5 = list(name = 'UBCF', param = list(nn = 5, method = "pearson", normalize = NULL)),
UBCF_jaccard_5 = list(name = 'UBCF', param = list(nn = 5, method = "jaccard", normalize = NULL))
)
#Create the algorithms
runRecommender <- function(method, scheme){
Recommender(getData(scheme, "train"), method[[1]])
}
#Get the RMSE and MAE of the algorithms
predError <- function(method, scheme){
print(show(method))
preds <- predict(method, getData(scheme, "known"), type="ratings")
rmse <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[1]]
mae <- calcPredictionAccuracy(preds, getData(scheme, "unknown"))[[3]]
merge(rmse, mae)
}
recs <- lapply(algorithm_list, runRecommender, ev_scheme)
#Get the errors and place in a data frame
recommender_errors <- sapply(recs, predError, ev_scheme) %>%
t() %>%
as.data.frame() %>%
rownames_to_column %>%
as_tibble() %>%
rename(Model = rowname, RMSE = x, MAE = y) %>%
mutate(RMSE = as.numeric(RMSE),
MAE = as.numeric(MAE)) %>%
arrange(RMSE, MAE)
View(recommender_errors)
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(nn = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% drop_na() %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(nn = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
?Recommender
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(k = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(k = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
View(data)
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(k = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
setwd("C:/Users/isaac/OneDrive/Documents/NYU/Spring_2018/c_1003/NYUMLProject")
for(year in 2013:2016){
readIn_path <- paste0('data/rec/before_dubIndex/data', year, '.csv')
readOut_path <- paste0('data/rec/after_dubIndex/data', year, '.csv')
data <- read_csv(readIn_path)
data_mat <- data %>% as.data.frame() %>% as("realRatingMatrix") %>% normalize(., method = "center", row = TRUE)
norm_info <- data_mat@normalize
ev_scheme <- evaluationScheme(data_mat, method = 'split', train = .8, given = -1)
fit <- Recommender(data_mat, method = "IBCF", param = list(k = 5, method = "pearson", normalize = NULL))
data2 <-  data %>% as.data.frame() %>% as("realRatingMatrix")
predicted <- predict(fit, data2, type = "ratings") %>% denormalize()
data_full <- as(data2@data + predicted@data, "realRatingMatrix")
as(data_full, 'data.frame') %>% write_csv(., readOut_path)
}
>dist
?dist
