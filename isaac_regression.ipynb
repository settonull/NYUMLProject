{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "ctmc_dir = 'ctmc'\n",
    "glicko_dir = 'glicko'\n",
    "curseason_dir = 'curseason'\n",
    "scorepreds_dir = 'scorepreds'\n",
    "ultimate_dir = 'ultimate'\n",
    "scores_pe_dir = 'scores_pe'\n",
    "bcs_dir = 'BCS'\n",
    "conf_dir = 'conferences'\n",
    "data_dir = os.path.join(root_dir, \"data\")\n",
    "\n",
    "##### IJH Data\n",
    "file = os.path.join(data_dir, ultimate_dir, \"ultimate_2.csv\")\n",
    "scores_pe_df = pd.read_csv(file)\n",
    "scores_pe_df = scores_pe_df.set_index(['HomeID', 'VisID', 'Season', 'Week'])\n",
    "scores_pe_df['target_margin'] = scores_pe_df['HomeFinal'] - scores_pe_df['VisFinal']\n",
    "scores_pe_df = scores_pe_df[['HomeElo', 'HomeEloProb','HomeLuck','HomePrevLuck',\n",
    "                            'HomePythPct','HomePythWins','HomeWinPct','VisElo',\n",
    "                            'VisEloProb','VisLuck', 'VisPrevLuck','VisPythPct',\n",
    "                            'VisPythWins','VisWinPct','SpreadElo','HomeConf_NotMajor',\n",
    "                            'VisConf_NotMajor','target_margin','HomeFinal','VisFinal']]\n",
    "scores_pe_df = scores_pe_df.drop_duplicates()\n",
    "\n",
    "######## SWC Data\n",
    "file = os.path.join(data_dir, ctmc_dir, \"scores_ctmc_ultimate_data_final.csv\")\n",
    "scores_ctmc_df = pd.read_csv(file,index_col=[0,1,2,3]).drop_duplicates()\n",
    "scores_ctmc_df.index.names = ['HomeID', 'VisID', 'Season', 'Week']\n",
    "file = os.path.join(data_dir, glicko_dir, \"glicko_ultimate_data_final.csv\")\n",
    "glicko_df = pd.read_csv(file, index_col=[0,1,2,3]).drop_duplicates()\n",
    "glicko_df.index.names = ['HomeID', 'VisID', 'Season', 'Week']\n",
    "file = os.path.join(data_dir, curseason_dir, \"curseason.csv\")\n",
    "curseason_df = pd.read_csv(file, index_col=[0,1,2,3]).drop_duplicates()\n",
    "file = os.path.join(data_dir, scorepreds_dir, \"scorepreds.csv\")\n",
    "scorepreds_df = pd.read_csv(file, index_col=[0,1,2,3]).drop_duplicates()\n",
    "\n",
    "# Join SC Data\n",
    "data_final = scores_pe_df.join(scores_ctmc_df, how='left')\n",
    "data_final = data_final.join(glicko_df)\n",
    "data_final = data_final.join(curseason_df)\n",
    "data_final = data_final.join(scorepreds_df, how='left')\n",
    "\n",
    "##### CDR Data\n",
    "file = os.path.join(data_dir, bcs_dir, \"BCS-SOS.csv\")\n",
    "bcs_df = pd.read_csv(file).drop_duplicates()\n",
    "bcs_df = bcs_df.set_index(['HomeID', 'VisID', 'Season', 'Week'])\n",
    "\n",
    "# Join CDR Data\n",
    "data_final = data_final.join(bcs_df)\n",
    "\n",
    "# Join Conference Data\n",
    "file = os.path.join(data_dir, conf_dir, \"mergedConferences.csv\")\n",
    "conf_df = pd.read_csv(file).drop_duplicates()\n",
    "data_final = data_final.reset_index().merge(conf_df,\n",
    "                                            left_on=['HomeID', 'Season'],\n",
    "                                            right_on=['ID','Year'],\n",
    "                                            suffixes=('','Home'))\n",
    "data_final = data_final.reset_index().merge(conf_df,\n",
    "                                            left_on=['VisID', 'Season'],\n",
    "                                            right_on=['ID','Year'],\n",
    "                                            suffixes=('','Vis'))\n",
    "data_final = data_final.set_index(['HomeID', 'VisID', 'Season', 'Week'])\n",
    "data_final = data_final.drop(['ID','Year','IDVis','index'],1)\n",
    "\n",
    "# Impute HomeConf Data\n",
    "data_final['HomeConf_NotMajor'] = data_final['HomeConf_NotMajor'].fillna(0)\n",
    "data_final['PredSpread'] = data_final['HomePredFinal'] - data_final['VisPredFinal']\n",
    "\n",
    "################################################################################\n",
    "# Train - Val - Test Splits\n",
    "################################################################################\n",
    "\n",
    "X_train = data_final[(data_final.index.get_level_values(2)<2016) & \\\n",
    "                     (data_final['Conf']!='NotMajor') &\n",
    "                     (data_final.index.get_level_values(3)>4)].\\\n",
    "                                       drop(['target_margin'], axis=1).\\\n",
    "                                       fillna(data_final.mean())\n",
    "y_train = data_final[(data_final.index.get_level_values(2)<2016) & \\\n",
    "                     (data_final['Conf']!='NotMajor') & \\\n",
    "                     (data_final.index.get_level_values(3)>4)]['target_margin']\n",
    "\n",
    "X_val = data_final[(data_final.index.get_level_values(2)==2016) & \\\n",
    "                   (data_final['Conf']!='NotMajor') & \\\n",
    "                   (data_final.index.get_level_values(3)>4)].\\\n",
    "                                     drop(['target_margin'], axis=1).\\\n",
    "                                     fillna(data_final.mean())\n",
    "y_val = data_final[(data_final.index.get_level_values(2)==2016) & \\\n",
    "                   (data_final['Conf']!='NotMajor') & \\\n",
    "                   (data_final.index.get_level_values(3)>4)]['target_margin']\n",
    "\n",
    "X_test = data_final[(data_final.index.get_level_values(2)==2017) & \\\n",
    "                    (data_final['Conf']!='NotMajor') & \\\n",
    "                    (data_final.index.get_level_values(3)>4)].\\\n",
    "                                      drop(['target_margin'], axis=1).\\\n",
    "                                      fillna(data_final.mean())\n",
    "y_test = data_final[(data_final.index.get_level_values(2)==2017) & \\\n",
    "                    (data_final['Conf']!='NotMajor') & \\\n",
    "                    (data_final.index.get_level_values(3)>4)]['target_margin']\n",
    "\n",
    "################################################################################\n",
    "# Final Feature Selection\n",
    "################################################################################\n",
    "\n",
    "base_featurestouse = [col for col in data_final.columns if \\\n",
    "                      col.find('InSeason') > -1]\n",
    "\n",
    "swc_featurestouse = ['Glicko_Rating_Home', 'Glicko_Rating_Away',\n",
    "                     'Glicko_Rating_Deviance_Home', 'Glicko_Rating_Deviance_Away',\n",
    "                     'Glicko_Sigma_Home', 'Glicko_Sigma_Away',\n",
    "                     'CTMC_Rating_Home', 'CTMC_Rating_Away','HomePredFinal',\n",
    "                     'VisPredFinal','CurSeason_HH_VA_mean_margin']\n",
    "\n",
    "ijh_featurestouse = ['HomeElo', 'HomeEloProb','HomeLuck','HomePrevLuck',\n",
    "                    'HomePythPct','HomePythWins','HomeWinPct','VisElo',\n",
    "                    'VisEloProb','VisLuck', 'VisPrevLuck','VisPythPct',\n",
    "                    'VisPythWins','VisWinPct','SpreadElo','HomeConf_NotMajor',\n",
    "                    'VisConf_NotMajor']\n",
    "\n",
    "cdr_featurestouse = bcs_df.columns.values.tolist()\n",
    "\n",
    "# featurestouse = base_featurestouse + swc_featurestouse + ijh_featurestouse + cdr_featurestouse\n",
    "featurestouse = swc_featurestouse + ijh_featurestouse + cdr_featurestouse\n",
    "featurestouse.append('PredSpread')\n",
    "\n",
    "################################################################################\n",
    "# Baseline Model\n",
    "################################################################################\n",
    "\n",
    "# Current season average margins diff\n",
    "X_train['CurSeason_HH_VA_mean_margin'] = (X_train['SpreadHomeInSeasonAvg'] \\\n",
    "                                    - X_train['SpreadVisInSeasonAvg']*-1)\n",
    "X_val['CurSeason_HH_VA_mean_margin'] = (X_val['SpreadHomeInSeasonAvg'] \\\n",
    "                                        - X_val['SpreadVisInSeasonAvg']*-1)\n",
    "X_test['CurSeason_HH_VA_mean_margin'] = (X_test['SpreadHomeInSeasonAvg'] \\\n",
    "                                        - X_test['SpreadVisInSeasonAvg']*-1)\n",
    "\n",
    "# Train and report baseline model with current season metric\n",
    "ols = LinearRegression()\n",
    "ols.fit(X_train['CurSeason_HH_VA_mean_margin'].values.reshape(-1,1), y_train)\n",
    "ols.score(X_train['CurSeason_HH_VA_mean_margin'].values.reshape(-1,1), y_train)\n",
    "ols.score(X_val['CurSeason_HH_VA_mean_margin'].values.reshape(-1,1), y_val)\n",
    "preds = ols.predict(X_val['CurSeason_HH_VA_mean_margin'].values.reshape(-1,1))\n",
    "mean_squared_error(preds, y_val)\n",
    "\n",
    "################################################################################\n",
    "# Standardize data\n",
    "################################################################################\n",
    "\n",
    "####### Scale data select features\n",
    "standardscaler = StandardScaler()\n",
    "X_trainscaled = standardscaler.fit_transform(X_train[featurestouse])\n",
    "X_valscaled = standardscaler.transform(X_val[featurestouse])\n",
    "X_testscaled = standardscaler.transform(X_test[featurestouse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression #penalty, C, \n",
    "from sklearn.linear_model import ElasticNet #alpha, l1_ratio, warm_start, \n",
    "from sklearn.svm import SVC #C, kernel, degree-polynomial, gamma, \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['HomeWin'] = data_final.apply(lambda x: 1 if x['target_margin'] > 0 else 0, axis=1)\n",
    "X_trainC = data_final[(data_final.index.get_level_values(2)<2016) & \\\n",
    "                     (data_final['Conf']!='NotMajor') &\n",
    "                     (data_final.index.get_level_values(3)>4)].\\\n",
    "                                       drop(['target_margin', 'HomeWin'], axis=1).\\\n",
    "                                       fillna(data_final.mean())\n",
    "y_trainC = data_final[(data_final.index.get_level_values(2)<2016) & \\\n",
    "                     (data_final['Conf']!='NotMajor') & \\\n",
    "                     (data_final.index.get_level_values(3)>4)]['HomeWin']\n",
    "\n",
    "X_valC = data_final[(data_final.index.get_level_values(2)==2016) & \\\n",
    "                   (data_final['Conf']!='NotMajor') & \\\n",
    "                   (data_final.index.get_level_values(3)>4)].\\\n",
    "                                     drop(['target_margin', 'HomeWin'], axis=1).\\\n",
    "                                     fillna(data_final.mean())\n",
    "y_valC = data_final[(data_final.index.get_level_values(2)==2016) & \\\n",
    "                   (data_final['Conf']!='NotMajor') & \\\n",
    "                   (data_final.index.get_level_values(3)>4)]['HomeWin']\n",
    "\n",
    "X_testC = data_final[(data_final.index.get_level_values(2)==2017) & \\\n",
    "                    (data_final['Conf']!='NotMajor') & \\\n",
    "                    (data_final.index.get_level_values(3)>4)].\\\n",
    "                                      drop(['target_margin', 'HomeWin'], axis=1).\\\n",
    "                                      fillna(data_final.mean())\n",
    "y_testC = data_final[(data_final.index.get_level_values(2)==2017) & \\\n",
    "                    (data_final['Conf']!='NotMajor') & \\\n",
    "                    (data_final.index.get_level_values(3)>4)]['HomeWin']\n",
    "\n",
    "# Current season average margins diff\n",
    "X_trainC['CurSeason_HH_VA_mean_margin'] = (X_trainC['SpreadHomeInSeasonAvg'] \\\n",
    "                                    - X_trainC['SpreadVisInSeasonAvg']*-1)\n",
    "X_valC['CurSeason_HH_VA_mean_margin'] = (X_valC['SpreadHomeInSeasonAvg'] \\\n",
    "                                        - X_valC['SpreadVisInSeasonAvg']*-1)\n",
    "X_testC['CurSeason_HH_VA_mean_margin'] = (X_testC['SpreadHomeInSeasonAvg'] \\\n",
    "                                        - X_testC['SpreadVisInSeasonAvg']*-1)\n",
    "\n",
    "\n",
    "featurestouse2 = ['Glicko_Rating_Home','Glicko_Rating_Away','Glicko_Rating_Deviance_Home','Glicko_Rating_Deviance_Away',\n",
    " 'Glicko_Sigma_Home','Glicko_Sigma_Away','CTMC_Rating_Home','CTMC_Rating_Away',\n",
    " 'CurSeason_HH_VA_mean_margin', 'PredSpread',\n",
    " 'HomeElo','HomeEloProb','HomeLuck','HomePrevLuck','HomePythPct','HomePythWins','HomeWinPct',\n",
    " 'VisElo','VisEloProb','VisLuck','VisPrevLuck','VisPythPct','VisPythWins','VisWinPct',\n",
    " 'SpreadElo','HomeConf_NotMajor','VisConf_NotMajor',\n",
    " 'HomeBCSSOS','HomeRPI','AwayBCSSOS','AwayRPI']\n",
    "\n",
    "standardscaler = StandardScaler()\n",
    "X_trainscaledC = standardscaler.fit_transform(X_trainC[featurestouse])\n",
    "X_valscaledC = standardscaler.transform(X_valC[featurestouse])\n",
    "X_testscaledC = standardscaler.transform(X_testC[featurestouse])\n",
    "\n",
    "X_trainscaledC2 = standardscaler.fit_transform(X_trainC[featurestouse2])\n",
    "X_valscaledC2 = standardscaler.transform(X_valC[featurestouse2])\n",
    "X_testscaledC2 = standardscaler.transform(X_testC[featurestouse2])\n",
    "\n",
    "dataDict = {'X_train':X_trainscaledC, 'X_val':X_valscaledC, 'X_train2':X_trainscaledC2, 'X_val2':X_valscaledC2,\n",
    "            'y_trainC':y_trainC, 'y_valC':y_valC, 'y_train':y_train, 'y_val':y_val}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chainedRegression(nameC, nameR, estimatorC, estimatorR, dataDict=dataDict, feats=False, est=False):\n",
    "    \n",
    "    if feats:\n",
    "        X_trainC2 = dataDict['X_train2'].copy()\n",
    "        X_valC2 = dataDict['X_val2'].copy()\n",
    "    else:\n",
    "        X_trainC2 = dataDict['X_train'].copy()\n",
    "        X_valC2 = dataDict['X_val'].copy()\n",
    "    \n",
    "    classifer = estimatorC.fit(X_trainC2, dataDict['y_trainC'])\n",
    "    predsTrain = classifer.predict_proba(X_trainC2)[:,1]\n",
    "    predsVal = classifer.predict_proba(X_valC2)[:,1]\n",
    "    print(nameC, roc_auc_score(dataDict['y_valC'], predsVal))\n",
    "    X_trainC2 = np.concatenate((X_trainC2, predsTrain.reshape(-1,1)), 1)\n",
    "    \n",
    "    X_valC2 = np.concatenate((X_valC2, predsVal.reshape(-1,1)), 1)\n",
    "    \n",
    "    if est:\n",
    "        X_trainC2 = np.concatenate((X_trainC2, np.where(predsTrain >0.5, 1, 0).reshape(-1,1)), 1)\n",
    "        X_valC2 = np.concatenate((X_valC2, np.where(predsVal >0.5, 1, 0).reshape(-1,1)), 1)\n",
    "    \n",
    "    regressor = estimatorR.fit(X_trainC2, dataDict['y_train'])\n",
    "    predsReg = regressor.predict(X_valC2)\n",
    "    print(nameR, mean_squared_error(dataDict['y_val'], predsReg))\n",
    "    \n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit1 0.8203282424714073\n",
      "KernelRidge1 277.11463569267886\n",
      "Logit2 0.8201336872385663\n",
      "KernelRidge1 277.15381310803093\n",
      "Logit1 0.8203282424714073\n",
      "KernelRidge2 277.0286763213798\n",
      "Logit2 0.8201336872385663\n",
      "KernelRidge2 277.05406977076245\n"
     ]
    }
   ],
   "source": [
    "logit_kr1 = chainedRegression('Logit1', 'KernelRidge1',\n",
    "                              LogisticRegression(C=0.1), KernelRidge(alpha=0.0001, gamma=1e-5),\n",
    "                              dataDict, False, False)\n",
    "\n",
    "logit_kr2 = chainedRegression('Logit2', 'KernelRidge1',\n",
    "                              LogisticRegression(C=0.1), KernelRidge(alpha=0.0001, gamma=1e-5),\n",
    "                              dataDict, True, False)\n",
    "\n",
    "logit_kr3 = chainedRegression('Logit1', 'KernelRidge2',\n",
    "                              LogisticRegression(C=0.1), KernelRidge(alpha=0.0001, gamma=1e-5),\n",
    "                              dataDict, False, True)\n",
    "\n",
    "logit_kr4 = chainedRegression('Logit2', 'KernelRidge2',\n",
    "                              LogisticRegression(C=0.1), KernelRidge(alpha=0.0001, gamma=1e-5),\n",
    "                              dataDict, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338.0486320337523"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(dataDict['y_val'], KernelRidge(alpha=0.0001, gamma=1e-5).fit(dataDict['X_train'][:,9].reshape(-1, 1), dataDict['y_train']).predict(dataDict['X_val'][:,9].reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314.50065455164804\n",
      "Feature ranking:\n",
      "1. PredSpread (0.512126)\n",
      "2. CurSeason_HH_VA_mean_margin (0.033038)\n",
      "3. HomePredFinal (0.030247)\n",
      "4. VisPredFinal (0.027358)\n",
      "5. VisPythWins (0.024368)\n",
      "6. VisPythPct (0.024131)\n",
      "7. Glicko_Sigma_Home (0.023550)\n",
      "8. Glicko_Rating_Away (0.023321)\n",
      "9. CTMC_Rating_Away (0.021645)\n",
      "10. VisElo (0.021572)\n",
      "11. Glicko_Sigma_Away (0.020074)\n",
      "12. HomePythWins (0.019631)\n",
      "13. Glicko_Rating_Home (0.019098)\n",
      "14. HomePythPct (0.019096)\n",
      "15. CTMC_Rating_Home (0.018839)\n",
      "16. HomeElo (0.018345)\n",
      "17. Glicko_Rating_Deviance_Home (0.018263)\n",
      "18. Glicko_Rating_Deviance_Away (0.018207)\n",
      "19. HomeBCSSOS (0.015169)\n",
      "20. AwayBCSSOS (0.013260)\n",
      "21. AwayRPI (0.010767)\n",
      "22. VisEloProb (0.010357)\n",
      "23. VisWinPct (0.010041)\n",
      "24. SpreadElo (0.009716)\n",
      "25. HomeEloProb (0.009478)\n",
      "26. HomeRPI (0.009321)\n",
      "27. HomeWinPct (0.009034)\n",
      "28. HomePrevLuck (0.002649)\n",
      "29. HomeLuck (0.002631)\n",
      "30. VisPrevLuck (0.002356)\n",
      "31. VisLuck (0.002307)\n",
      "32. VisConf_NotMajor (0.000003)\n",
      "33. HomeConf_NotMajor (0.000000)\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(min_samples_split=10).fit(dataDict['X_train'], dataDict['y_train'])\n",
    "print(mean_squared_error(dataDict['y_val'], rfr.predict(dataDict['X_val'])))\n",
    "\n",
    "importances = rfr.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfr.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(dataDict['X_train'].shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, featurestouse[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299.45737193475327\n",
      "Feature ranking:\n",
      "1. PredSpread (0.534885)\n",
      "2. CurSeason_HH_VA_mean_margin (0.033658)\n",
      "3. VisPythPct (0.025309)\n",
      "4. HomePythPct (0.025081)\n",
      "5. CTMC_Rating_Home (0.024776)\n",
      "6. CTMC_Rating_Away (0.024658)\n",
      "7. Glicko_Rating_Away (0.024461)\n",
      "8. Glicko_Rating_Home (0.023823)\n",
      "9. HomePythWins (0.022531)\n",
      "10. Glicko_Sigma_Home (0.022097)\n",
      "11. VisPythWins (0.020667)\n",
      "12. VisElo (0.020454)\n",
      "13. Glicko_Sigma_Away (0.020385)\n",
      "14. Glicko_Rating_Deviance_Away (0.018933)\n",
      "15. Glicko_Rating_Deviance_Home (0.018644)\n",
      "16. HomeElo (0.017466)\n",
      "17. HomeBCSSOS (0.015095)\n",
      "18. AwayBCSSOS (0.014990)\n",
      "19. VisWinPct (0.013045)\n",
      "20. AwayRPI (0.011996)\n",
      "21. VisEloProb (0.011470)\n",
      "22. HomeEloProb (0.011155)\n",
      "23. HomeWinPct (0.010838)\n",
      "24. HomeRPI (0.010537)\n",
      "25. SpreadElo (0.010086)\n",
      "26. HomeLuck (0.003515)\n",
      "27. HomePrevLuck (0.003252)\n",
      "28. VisLuck (0.003063)\n",
      "29. VisPrevLuck (0.003012)\n",
      "30. VisConf_NotMajor (0.000118)\n",
      "31. HomeConf_NotMajor (0.000000)\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(min_samples_split=10).fit(dataDict['X_train2'], dataDict['y_train'])\n",
    "print(mean_squared_error(dataDict['y_val'], rfr.predict(dataDict['X_val2'])))\n",
    "\n",
    "importances = rfr.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfr.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(dataDict['X_train2'].shape[1]):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, featurestouse2[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doGridSearchC(X_train, y_train, X_val, y_val, model, param_grid, scorer):\n",
    "    X_train_val = np.vstack((X_train, X_val))\n",
    "    y_train_val = np.concatenate((y_train, y_val))\n",
    "    val_fold = [-1]*len(X_train) + [0]*len(X_val) #0 corresponds to validation\n",
    "    estimator = model.fit(X_train, y_train)\n",
    "    grid = GridSearchCV(estimator,\n",
    "                        param_grid,\n",
    "                        return_train_score=False,\n",
    "                        cv = PredefinedSplit(test_fold=val_fold),\n",
    "                        refit = True,\n",
    "                        scoring = scorer)\n",
    "    grid.fit(X_train_val, y_train_val)\n",
    "    return grid.best_estimator_\n",
    "\n",
    "def chainClassiferGridSearch(nameC, nameR, estimatorC, estimatorR, paramC, dataDict=dataDict, feats=False, est=False):\n",
    "\n",
    "    scorer = make_scorer(roc_auc_score, greater_is_better = True)\n",
    "    \n",
    "    if feats:\n",
    "        X_trainC2 = dataDict['X_train2'].copy()\n",
    "        X_valC2 = dataDict['X_val2'].copy()\n",
    "    else:\n",
    "        X_trainC2 = dataDict['X_train'].copy()\n",
    "        X_valC2 = dataDict['X_val'].copy()\n",
    "    \n",
    "    classifer = doGridSearchC(X_trainC2, dataDict['y_trainC'], X_valC2, dataDict['y_valC'], estimatorC, paramC, scorer)\n",
    "    classifer = classifer.fit(X_trainC2, dataDict['y_trainC'])\n",
    "    predsTrain = classifer.predict_proba(X_trainC2)[:,1]\n",
    "    predsVal = classifer.predict_proba(X_valC2)[:,1]\n",
    "    print(nameC, roc_auc_score(dataDict['y_valC'], predsVal))\n",
    "\n",
    "    X_trainC2 = np.concatenate((X_trainC2, predsTrain.reshape(-1,1)), 1)\n",
    "    X_valC2 = np.concatenate((X_valC2, predsVal.reshape(-1,1)), 1)\n",
    "    \n",
    "    if est:\n",
    "        X_trainC2 = np.concatenate((X_trainC2, np.where(predsTrain >0.5, 1, 0).reshape(-1,1)), 1)\n",
    "        X_valC2 = np.concatenate((X_valC2, np.where(predsVal >0.5, 1, 0).reshape(-1,1)), 1)\n",
    "\n",
    "    regressor = estimatorR.fit(X_trainC2, dataDict['y_train'])\n",
    "    predsReg = regressor.predict(X_valC2)\n",
    "    print(nameR, mean_squared_error(dataDict['y_val'], predsReg))\n",
    "    return(clssifer)\n",
    "\n",
    "def chainRegressorGridSearch(nameC, nameR, estimatorC, estimatorR, paramR, dataDict=dataDict, feats=False, est=False):\n",
    "\n",
    "    scorer = make_scorer(mean_squared_error, greater_is_better = False)\n",
    "    \n",
    "    if feats:\n",
    "        X_trainC2 = dataDict['X_train2'].copy()\n",
    "        X_valC2 = dataDict['X_val2'].copy()\n",
    "    else:\n",
    "        X_trainC2 = dataDict['X_train'].copy()\n",
    "        X_valC2 = dataDict['X_val'].copy()\n",
    "    \n",
    "    classifer = estimatorC.fit(X_trainC2, dataDict['y_trainC'])\n",
    "    predsTrain = classifer.predict_proba(X_trainC2)[:,1]\n",
    "    predsVal = classifer.predict_proba(X_valC2)[:,1]\n",
    "    print(nameC, roc_auc_score(dataDict['y_valC'], predsVal))\n",
    "\n",
    "    X_trainC2 = np.concatenate((X_trainC2, predsTrain.reshape(-1,1)), 1)\n",
    "    X_valC2 = np.concatenate((X_valC2, predsVal.reshape(-1,1)), 1)\n",
    "    \n",
    "    if est:\n",
    "        X_trainC2 = np.concatenate((X_trainC2, np.where(predsTrain >0.5, 1, 0).reshape(-1,1)), 1)\n",
    "        X_valC2 = np.concatenate((X_valC2, np.where(predsVal >0.5, 1, 0).reshape(-1,1)), 1)\n",
    "    \n",
    "    regressor = doGridSearchC(X_trainC2, dataDict['y_train'], X_valC2, dataDict['y_val'], estimatorR, paramR, scorer)\n",
    "    regressor = regressor.fit(X_trainC2, dataDict['y_train'])\n",
    "    predsReg = regressor.predict(X_valC2)\n",
    "    print(nameR, mean_squared_error(dataDict['y_val'], predsReg))\n",
    "    return(regressor)\n",
    "\n",
    "\n",
    "def chainDoubleGridSearch(nameC, nameR, estimatorC, estimatorR, paramC, paramR, dataDict=dataDict, feats=False, est=False):\n",
    "\n",
    "    scorerC = make_scorer(roc_auc_score, greater_is_better = True)\n",
    "    scorerR = make_scorer(mean_squared_error, greater_is_better = False)    \n",
    "    \n",
    "    if feats:\n",
    "        X_trainC2 = dataDict['X_train2'].copy()\n",
    "        X_valC2 = dataDict['X_val2'].copy()\n",
    "    else:\n",
    "        X_trainC2 = dataDict['X_train'].copy()\n",
    "        X_valC2 = dataDict['X_val'].copy()\n",
    "    \n",
    "    classifer = doGridSearchC(X_trainC2, dataDict['y_trainC'], X_valC2, dataDict['y_valC'], estimatorC, paramC, scorerC)\n",
    "    classifer = classifer.fit(X_trainC2, dataDict['y_trainC'])\n",
    "    predsTrain = classifer.predict_proba(X_trainC2)[:,1]\n",
    "    predsVal = classifer.predict_proba(X_valC2)[:,1]\n",
    "    print(nameC, roc_auc_score(dataDict['y_valC'], predsVal))\n",
    "\n",
    "    X_trainC2 = np.concatenate((X_trainC2, predsTrain.reshape(-1,1)), 1)\n",
    "    X_trainC2 = np.concatenate((X_trainC2, np.where(predsTrain >0.5, 1, 0).reshape(-1,1)), 1)\n",
    "    X_valC2 = np.concatenate((X_valC2, predsVal.reshape(-1,1)), 1)\n",
    "    X_valC2 = np.concatenate((X_valC2, np.where(predsVal >0.5, 1, 0).reshape(-1,1)), 1)\n",
    "\n",
    "    regressor = doGridSearchC(X_trainC2, dataDict['y_train'], X_valC2, dataDict['y_val'], estimatorR, paramR, scorerR)\n",
    "    regrsregressorsor = regressor.fit(X_trainC2, dataDict['y_train'])\n",
    "    predsReg = regressor.predict(X_valC2)\n",
    "    print(nameR, mean_squared_error(dataDict['y_val'], predsReg))\n",
    "    return(classifer, regressor)\n",
    "\n",
    "def chainGridSearchWrapper(nameC, nameR, clssfier, estimatorC, estimatorR, params, dataDict=dataDict, feats=False, est=False):\n",
    "    if len(params) == 2:\n",
    "        return chainDoubleGridSearch(nameC, nameR, estimatorC, estimatorR, params[0], params[1], dataDict, feats, est)\n",
    "    elif clssfier:\n",
    "        return chainClassiferGridSearch(nameC, nameR, estimatorC, estimatorR, params, dataDict, feats, est)\n",
    "    else:\n",
    "        return chainRegressorGridSearch(nameC, nameR, estimatorC, estimatorR, params, dataDict, feats, est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit1 0.820036409622146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-38644d65ecbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                           [{'alpha':10**np.arange(-5, 1, 1.0),\n\u001b[0;32m      5\u001b[0m                            'gamma':10**np.arange(-5, 1, 1.0)}]], \n\u001b[1;32m----> 6\u001b[1;33m                           dataDict, False, False)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-97-95b6fb6de795>\u001b[0m in \u001b[0;36mchainGridSearchWrapper\u001b[1;34m(nameC, nameR, clssfier, estimatorC, estimatorR, params, dataDict, feats, est)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchainGridSearchWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnameC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnameR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclssfier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimatorC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimatorR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataDict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mchainDoubleGridSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnameC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnameR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimatorC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimatorR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mclssfier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mchainClassiferGridSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnameC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnameR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimatorC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimatorR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-97-95b6fb6de795>\u001b[0m in \u001b[0;36mchainDoubleGridSearch\u001b[1;34m(nameC, nameR, estimatorC, estimatorR, paramC, paramR, dataDict, feats, est)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mX_valC2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valC2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredsVal\u001b[0m \u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[0mregressor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoGridSearchC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trainC2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valC2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimatorR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparamR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorerR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[0mregrsregressorsor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trainC2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mpredsReg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valC2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-97-95b6fb6de795>\u001b[0m in \u001b[0;36mdoGridSearchC\u001b[1;34m(X_train, y_train, X_val, y_val, model, param_grid, scorer)\u001b[0m\n\u001b[0;32m     10\u001b[0m                         \u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                         scoring = scorer)\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\kernel_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    160\u001b[0m         self.dual_coef_ = _solve_cholesky_kernel(K, y, alpha,\n\u001b[0;32m    161\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m                                                  copy)\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mravel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py\u001b[0m in \u001b[0;36m_solve_cholesky_kernel\u001b[1;34m(K, y, alpha, sample_weight, copy)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[1;31m#       is raised\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             dual_coef = linalg.solve(K, y, sym_pos=True,\n\u001b[1;32m--> 152\u001b[1;33m                                      overwrite_a=False)\n\u001b[0m\u001b[0;32m    153\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             warnings.warn(\"Singular matrix in solving dual problem. Using \"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\linalg\\basic.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(a, b, sym_pos, lower, overwrite_a, overwrite_b, debug, check_finite, assume_a, transposed)\u001b[0m\n\u001b[0;32m    248\u001b[0m         lu, x, info = posv(a1, b1, lower=lower,\n\u001b[0;32m    249\u001b[0m                            \u001b[0moverwrite_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverwrite_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                            overwrite_b=overwrite_b)\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0m_solve_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mrcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpocon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logit_kr1 = chainGridSearchWrapper('Logit1', 'KernelRidge1', False,\n",
    "                          LogisticRegression(), KernelRidge(),\n",
    "                          [[{'C':10**np.arange(-5, 1, 1.0)}],\n",
    "                          [{'alpha':10**np.arange(-5, 1, 1.0),\n",
    "                           'gamma':10**np.arange(-5, 1, 1.0)}]], \n",
    "                          dataDict, False, False)\n",
    "\n",
    "logit_kr2 = chainGridSearchWrapper('Logit2', 'KernelRidge1', False,\n",
    "                          LogisticRegression(), KernelRidge(),\n",
    "                          [[{'C':10**np.arange(-5, 1, 1.0)}],\n",
    "                          [{'alpha':10**np.arange(-5, 1, 1.0),\n",
    "                           'gamma':10**np.arange(-5, 1, 1.0)}]], \n",
    "                          dataDict, True, False)\n",
    "\n",
    "logit_kr3 = chainGridSearchWrapper('Logit1', 'KernelRidge2', False,\n",
    "                          LogisticRegression(), KernelRidge(),\n",
    "                          [[{'C':10**np.arange(-5, 1, 1.0)}],\n",
    "                          [{'alpha':10**np.arange(-5, 1, 1.0),\n",
    "                           'gamma':10**np.arange(-5, 1, 1.0)}]], \n",
    "                          dataDict, False, True)\n",
    "\n",
    "logit_kr4 = chainGridSearchWrapper('Logit2', 'KernelRidge2', False,\n",
    "                          LogisticRegression(), KernelRidge(),\n",
    "                          [[{'C':10**np.arange(-5, 1, 1.0)}],\n",
    "                          [{'alpha':10**np.arange(-5, 1, 1.0),\n",
    "                           'gamma':10**np.arange(-5, 1, 1.0)}]], \n",
    "                          dataDict, True, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
